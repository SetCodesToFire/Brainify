{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain MRI scans classifier\n",
    "\n",
    "This project is inteded to classify the brain mri as bold or t1w images. \n",
    "The dataset is taken from the openfmri https://openfmri.org/dataset/ds000243/ . These 120 MRI datasets are being released to the public along as part of the materials for “Temporal interpolation alters motion in fMRI scans: magnitudes and consequences for artifact detection” by Power et al. in PLOS ONE.\n",
    "\n",
    "Included for each subject is a T1-weighted anatomical image (MP-RAGE) and one or more T2*-weighted scans (resting state BOLD scans)\n",
    "\n",
    "All subjects \n",
    "    - were “typical” young adults that reported no significant neurological or psychiatric history\n",
    "    - were right-handed and reported that English was their first language\n",
    "    - were scanned at Washington University in Saint Louis on a Siemens MAGNETOM Tim Trio 3T scanner with a Siemens 12-channel head coil\n",
    "    - were scanned using interleaved ascending product sequences for T2* data\n",
    "    - were scanned in the eyes-open resting state fixating a white crosshair on a black background\n",
    "\n",
    "The data have been described in multiple publications from the Petersen/Schlaggar group,\n",
    "    - beginning with Power et al., 2013 “Evidence for hubs in human brain networks” in Neuron\n",
    "    - and most comprehensively in Power et al., 2014 “Methods to detect, characterize, and remove motion artifact in resting state fMRI” in Neuroimage\n",
    "    - as well as several other publications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for making the model\n",
    "\n",
    "    - Preprocessing the data\n",
    "    - Making a deep neural network and feeding the data to it\n",
    "    - Training the model\n",
    "    - Making a model.py file that would use the new inputs and predict the desired label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preprocessing the data\n",
    "\n",
    "The dataset we have is a 3D cube of the subject's MRI images and for bold images these are also 4D image where the 4th dimension is the time. Every subject was split into slices of images. Then these slices were coupled with the respective label and made a new .npy file that stores the images and its label as array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "IMG_PX_SIZE = 80\n",
    "HM_SLICES = 16\n",
    "\n",
    "data_dir = 'C:/users/setcodestofire/documents/mygithub/brain/FinalData'\n",
    "dataset  = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "def process_data(data):\n",
    "    \n",
    "    path = data_dir +'/'+ data\n",
    "    img3d = nib.load(path)\n",
    "    a = np.array(img3d.get_data())\n",
    "    \n",
    "    slice_img=[]\n",
    "    \n",
    "    if \"bold\" not in data:\n",
    "        label = [0,1]\n",
    "        for i in range(a.shape[2]):\n",
    "            slice_img.append(cv2.resize(np.array(a[:,:,i]),(IMG_PX_SIZE,IMG_PX_SIZE)))    \n",
    "    else:\n",
    "        label = [1,0]  \n",
    "        for i in range(a.shape[2]):\n",
    "            slice_img.append(cv2.resize(np.array(a[:,:,i,0]),(IMG_PX_SIZE,IMG_PX_SIZE)))\n",
    "    \n",
    "    \n",
    "    new_slices = []\n",
    "    \n",
    "    chunk_sizes = math.ceil(len(slice_img) / HM_SLICES)\n",
    "    for slice_chunk in chunks(slice_img, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "    \n",
    "    return np.array(new_slices),np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "much_data = []\n",
    "\n",
    "for data in dataset:\n",
    "    img_data,label = process_data(data)\n",
    "    for j in range(16):\n",
    "        much_data.append([img_data[j],label])\n",
    "\n",
    "np.save('muchdata-{}-{}-{}.npy'.format(IMG_PX_SIZE,IMG_PX_SIZE,HM_SLICES), much_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Making the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are making a deep neural network that will train on the processed data. The network includes 4 hidden layer and one fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "IMG_PX_SIZE = 80\n",
    "HM_SLICES = 16\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'boldvst1w-{}-{}.model.tflearn'.format(LR, '2conv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From c:\\users\\setcodestofire\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load('muchdata-80-80-16.npy')\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None,IMG_PX_SIZE,IMG_PX_SIZE,1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet,2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR,loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-400]\n",
    "test = train_data[-400:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1, IMG_PX_SIZE,IMG_PX_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1, IMG_PX_SIZE,IMG_PX_SIZE, 1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.10928\u001b[0m\u001b[0m | time: 123.389s\n",
      "| Adam | epoch: 003 | loss: 0.10928 - acc: 0.9940 -- iter: 3392/3440\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.09844\u001b[0m\u001b[0m | time: 130.018s\n",
      "| Adam | epoch: 003 | loss: 0.09844 - acc: 0.9946 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 3440/3440\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input':X},{'targets': Y}, n_epoch=3, validation_set=({'input':test_x},{'targets':test_y}),\n",
    "         snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\setCodesToFire\\Documents\\MyGithub\\Brain\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model accuracy reached 99.46%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"tensorflow-1.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
